<!DOCTYPE html>
<html  lang="zh-CN" >
<head>
  <meta charset="UTF-8">
  <meta name="viewport"
    content="width=device-width, initial-scale=1.0, minimum-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <meta name="theme-color" content="#fff" id="theme-color">
  <meta name="description" content="网络安全 Android ML CTF">
  <link rel="icon" href="/images/logo.png">
  <title>Meta Learning-Metric-based</title>
  
  
  <meta property="og:title" content="Meta Learning-Metric-based">
  
  
  <meta property="og:url" content="https://ch3nye.top/Meta-Learning-Metric-based/index.html">
  
  
  <meta property="og:img" content="/images/logo.png">
  
  
  <meta property="og:img" content="网络安全 Android ML CTF">
  
  
  <meta property="og:type" content="article">
  <meta property="og:article:published_time" content="2020-12-08">
  <meta property="og:article:modified_time" content="2020-12-08">
  <meta property="og:article:author" content="Ch3nYe">
  
  
  <meta property="og:article:tag" content="ML">
  
  <meta property="og:article:tag" content="note">
  
  <meta property="og:article:tag" content="Next-Step-of-ML">
  
  
  
  
  <script>
    // control reverse button
    var reverseDarkList = {
      dark: 'light',
      light: 'dark'
    };
    var themeColor = {
      dark: '#1c1c1e',
      light: '#fff'
    }
    // get the data of css prefers-color-scheme
    var getCssMediaQuery = function() {
      return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';
    };
    // reverse current darkmode setting function
    var reverseDarkModeSetting = function() {
      var setting = localStorage.getItem('user-color-scheme');
      if(reverseDarkList[setting]) {
        setting = reverseDarkList[setting];
      } else if(setting === null) {
        setting = reverseDarkList[getCssMediaQuery()];
      } else {
        return;
      }
      localStorage.setItem('user-color-scheme', setting);
      return setting;
    };
    // apply current darkmode setting
    var setDarkmode = function(mode) {
      var setting = mode || localStorage.getItem('user-color-scheme');
      if(setting === getCssMediaQuery()) {
        document.documentElement.removeAttribute('data-user-color-scheme');
        localStorage.removeItem('user-color-scheme');
        document.getElementById('theme-color').content = themeColor[setting];
      } else if(reverseDarkList[setting]) {
        document.documentElement.setAttribute('data-user-color-scheme', setting);
        document.getElementById('theme-color').content = themeColor[setting];
      } else {
        document.documentElement.removeAttribute('data-user-color-scheme');
        localStorage.removeItem('user-color-scheme');
        document.getElementById('theme-color').content = themeColor[getCssMediaQuery()];
      }
    };
    setDarkmode();
  </script>
  <script>
    function loadScript(url, cb) {
      var script = document.createElement('script');
      script.src = url;
      if (cb) script.onload = cb;
      script.async = true;
      document.body.appendChild(script);
    }
  </script>
  
  <link rel="preload" href="//at.alicdn.com/t/font_1946621_f7g5jnuftcf.css" as="style" >
  <link rel="preload" href="//at.alicdn.com/t/font_1952792_89b4ac4k4up.css" as="style" >
  
  <link rel="preload" href="//cdn.jsdelivr.net/npm/fslightbox@3.1.0/index.min.js" as="script">
  
  
  <link rel="preload" href="/js/lib/lozad.min.js" as="script">
  
  
  
  
  
  <link rel="prefetch" href="//cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" as="script">
  
  
  
  <link rel="prefetch" href="//cdn-city.livere.com/js/embed.dist.js" as="script">
  
  
  
  
<link rel="stylesheet" href="/css/main.css">

  
  
<link rel="stylesheet" href="//at.alicdn.com/t/font_1946621_f7g5jnuftcf.css">

  
  
<link rel="stylesheet" href="//at.alicdn.com/t/font_1952792_89b4ac4k4up.css">

  
  
  
  
  
  <link href="/js/lib/prism/prism-tomorrow.min.css" rel="stylesheet" data-prism="prism-tomorrow">
  
  
  
<link rel="stylesheet" href="/js/lib/prism/prism-line-numbers.min.css">

  
  
  
<meta name="generator" content="Hexo 5.3.0"></head>


<body>
  <div class="wrapper">
    
    <nav class="navbar">
  <div class="navbar-logo">
    <span class="navbar-logo-main">
      
      <img class="navbar-logo-img" src="/images/logo.png" alt="logo">
      
      <span class="navbar-logo-dsc">ch3nye's blog</span>
    </span>
  </div>
  <div class="navbar-menu">
    
    <a href="/" class="navbar-menu-item">
    
    首页
    
    </a>
    
    <a href="/archives" class="navbar-menu-item">
    
    归档
    
    </a>
    
    <a href="/tags" class="navbar-menu-item">
    
    标签
    
    </a>
    
    <a href="/categories" class="navbar-menu-item">
    
    分类
    
    </a>
    
    <a href="/about" class="navbar-menu-item">
    
    关于
    
    </a>
    
    <a href="/links" class="navbar-menu-item">
    
    友链
    
    </a>
    
    <a class="navbar-menu-item darknavbar" id="dark"><i class="iconfont icon-weather"></i></a>
    <a class="navbar-menu-item searchnavbar" id="search"><i class="iconfont icon-search" style="font-size: 1.2rem; font-weight: 400;"></i></a>
  </div>
</nav>
    
    <div id="local-search" style="display: none;">
      <input class="navbar-menu-item" id="search-input" placeholder="请输入搜索内容...">
      <div id="search-content"></div>
    </div>
    
    <div class="section-wrap">
      <div class="container">
        <div class="columns">
          <main class="main-column">
<article class="card card-content">
  <header>
    <h1 class="post-title">
      Meta Learning-Metric-based
    </h1>
  </header>
  <div class="post-meta post-show-meta">
    <time datetime="2020-12-07T16:00:00.000Z">
      <i class="iconfont icon-calendar" style="margin-right: 2px;"></i>
      <span>2020-12-08</span>
    </time>
    
    <span class="dot"></span>
    
    <a href="/categories/李宏毅机器学习笔记/" class="post-meta-link">李宏毅机器学习笔记</a>
    
    
    
    <span class="dot"></span>
    <span>2.8k 字</span>
    
  </div>
  
  <div class="post-meta post-show-meta" style="margin-top: -10px;">
    <div style="display: flex; align-items: center;">
      <i class="iconfont icon-biaoqian" style="margin-right: 2px; font-size: 1.15rem;"></i>
      
      
        <a href="/tags/ML/" class="post-meta-link">ML</a>
      
      
      <span class="dot"></span>
      
        <a href="/tags/note/" class="post-meta-link">note</a>
      
      
      <span class="dot"></span>
      
        <a href="/tags/Next-Step-of-ML/" class="post-meta-link">Next-Step-of-ML</a>
      
    </div>
  </div>
  
  </header>
  <div id="section" class="post-content">
    <h1 id="meta-learning-metric-based-approach"><a class="markdownIt-Anchor" href="#meta-learning-metric-based-approach"></a> Meta Learning-Metric-based Approach</h1>
<p>加下来我们就要实践我们之前提到的疯狂的想法：直接学一个function，输入训练数据和对应的标签，以及测试数据，直接输出测试数据的预测结果。也就是说这个模型把训练和预测一起做了。</p>
<p><img src="/images/image-20201207094523732.png" alt="image-20201207094523732" / srcset="/images/LoadingImage.gif" data-src="/images/image-20201207094523732.png" class="lozad post-image"></p>
<p>虽然这个想法听起很不错，好像挺难的，但是实际上现实生活中有在使用这样的技术，举例来说：手机的人脸验证</p>
<p><img src="/images/image-20201207094847250.png" alt="image-20201207094847250" / srcset="/images/LoadingImage.gif" data-src="/images/image-20201207094847250.png" class="lozad post-image"></p>
<p>我们在使用手机人脸解锁的时候需要录制人脸信息，这个过程中我们转动头部，就是手机在收集资料，收集到的资料就是作为few-shot learning 的训练资料。另外，语音解锁Speaker Verification 也是一样的技术，只要换一下输入资料和network 的架构。</p>
<p>这里需要注意Face Verification 和Face Recognition 是不一样的，前者是说给你一张人脸，判定是否是指定的人脸，比如人脸验证来解锁设备；后者是辨别一个人脸是人脸集合里面谁，比如公司人脸签到打卡。</p>
<p>下面我们就以Face Verification 为例，讲一下Metric-based Meta Learning</p>
<h2 id="training-tasks-testing-tasks"><a class="markdownIt-Anchor" href="#training-tasks-testing-tasks"></a> Training Tasks &amp; Testing Tasks</h2>
<p><img src="/images/image-20201207100158784.png" alt="image-20201207100158784" / srcset="/images/LoadingImage.gif" data-src="/images/image-20201207100158784.png" class="lozad post-image"></p>
<p>训练任务集中的任务都是人脸辨识数据，每个任务的测试集就是某个人的面部数据，测试集就是按标准（如手机录制人脸）收集的人脸数据，如果这个人和训练集相同就打一个Yes 标签，否则就打一个No 标签。测试任务和训练任务类似。总的来说，network 就是吃训练的人脸和测试的人脸，它会告诉你Yes or No 。</p>
<h2 id="siamese-network"><a class="markdownIt-Anchor" href="#siamese-network"></a> Siamese Network</h2>
<p>实际上是怎么做的呢，使用的技术是Siamese Network（孪生网络）。</p>
<p><img src="/images/image-20201207103516598.png" alt="image-20201207103516598" / srcset="/images/LoadingImage.gif" data-src="/images/image-20201207103516598.png" class="lozad post-image"></p>
<p>Siamese Network 的结构如上图所示，两个网络往往是共享参数的，根据需要有时候也可以不共享，假如说你现在觉得Training data 和Testing data 在形态上有比较大的区别，那你就可以不共享两个网路的参数。</p>
<p>从两个CNN 中抽出两个embedding ，然后计算这两个embedding 的相似度，比如说计算conference similarity 或者Euclidean Distance ，你得到一个数值score ，这个数值大就代表Network 的输出是Yes ，如果数值小就代表输出是No 。</p>
<h2 id="siamese-network-intuitive-explanation"><a class="markdownIt-Anchor" href="#siamese-network-intuitive-explanation"></a> Siamese Network - Intuitive Explanation</h2>
<p>接下来从直觉上来解释一下孪生网络。</p>
<p><img src="/images/image-20201207104440015.png" alt="image-20201207104440015" / srcset="/images/LoadingImage.gif" data-src="/images/image-20201207104440015.png" class="lozad post-image"></p>
<p>如上图所示，你可以把Siamese Network 看成一个二分类器，他就是吃进去两张人脸比较一下相似度，然后告诉我们Yes or No 。这样解释会比从Meta Learning 的角度来解释更容易理解。</p>
<p><img src="/images/image-20201207104643078.png" alt="image-20201207104643078" / srcset="/images/LoadingImage.gif" data-src="/images/image-20201207104643078.png" class="lozad post-image"></p>
<p>如上图所示，Siamese Network 做的事情就是把人脸投影到一个空间上，在这个空间上只要是同一个人的脸，不管他是往哪边看，不管机器看到的是他的哪一侧脸，都能被投影到这个空间的同一个位置上。</p>
<p>那你就会想了，这种图片降维的方法，这和Auto-Encoder 有什么区别呢，他比Auto-Encoder 好在哪？</p>
<p>你想你在做Auto-Encoder 的时候network 不知道你要解的任务是什么，它会尽可能记住图片中所有的信息，但是它不知道什么样的信息是重要的什么样的信息是不重要的。上图右侧，如果用Auto-Encoder 它可能会认为一花（左下）和三玖（右上）是比较接近的，因为他们的背景相似，这好吗，这不好。在Siamese Network 中，因为你要求network 把一花（左下）和三玖（右上）拉远，把三玖（右上）和三玖（右下）拉近，它可能会学会更加注意头发颜色的信息要忽略背景的信息。</p>
<h2 id="to-learn-more"><a class="markdownIt-Anchor" href="#to-learn-more"></a> To learn more…</h2>
<ul>
<li>What kind of distance should we use?
<ul>
<li>SphereFace: Deep Hypersphere Embedding for Face Recognition</li>
<li>Additive Margin Softmax for Face Verification</li>
<li>ArcFace: Additive Angular Margin Loss for Deep Face Recognition</li>
</ul>
</li>
<li>Triplet loss（三元是指：Data 可以包括训练人脸，正确的测试人脸，错误的测试人脸）
<ul>
<li>Deep Metric Learning using Triplet Network</li>
<li>FaceNet: A Unified Embedding for Face Recognition and Clustering</li>
</ul>
</li>
</ul>
<h2 id="n-way-fewone-shot-learning"><a class="markdownIt-Anchor" href="#n-way-fewone-shot-learning"></a> N-way Few/One-shot Learning</h2>
<p>刚才的栗子中，训练资料都只有一张，机器只要回答Yes or No 。那现在如果是一个分类的问题呢？现在我们打算把同样的概念用在5-way 1-shot 的任务上该怎么办呢？</p>
<p><img src="/images/image-20201207140825198.png" alt="image-20201207140825198" / srcset="/images/LoadingImage.gif" data-src="/images/image-20201207140825198.png" class="lozad post-image"></p>
<p>5-way 1-shot 就是说5个类别，每个类别中只有1个样本。就比如说上图，《五等分花嫁》中的五姐妹，要训一个模型分辨一个人脸是其中的谁，而训练资料是每个人只有一个样本。我们期待做到的事情是，Network 就把这五张带标签的训练图片外加一张测试图片都吃进去，然后模型就会告诉我们测试图片的分辨结果。</p>
<p>那模型的架构要怎么设计呢，比如说一个经典的设计：</p>
<h3 id="prototypical-network"><a class="markdownIt-Anchor" href="#prototypical-network"></a> Prototypical Network</h3>
<p>这是一个经典的做法：</p>
<p><img src="/images/image-20201207142707164.png" alt="image-20201207142707164" / srcset="/images/LoadingImage.gif" data-src="/images/image-20201207142707164.png" class="lozad post-image"></p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1703.05175">https://arxiv.org/abs/1703.05175</a></p>
</blockquote>
<p>这个方法和Siamese Network 非常相似，只不过从input 一张training data 扩展到input 多张training data 。</p>
<p>来解释一下这个方法，如上图所示，把每张图片丢到同一个CNN 中算出一个embedding 用橙色条表示，然后把测试图片的embedding 和所有训练图片的embedding 分别算出一个相似度 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>s</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">s_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 。黄色的方块表示计算相似度。接下来，取一个softmax ，这样就可以和正确的标签做cross entropy ，去minimize cross entropy，这就和一般的分类问题的loss function 相同的，就可以根据这个loss 做一次gradient descent ，因为是1-shot 所以只能做一次参数更新。</p>
<p><mark>？？？？这里有问题呀，如果testing data 是已知标签的数据，用来做了1-shot，那真正的要预测的数据呢？？？？？</mark></p>
<p><mark>如果你看明白了，请务必教教我🙏🙏🙏发邮件@sud0su@163.com或者加我Q@2948335218</mark></p>
<p>那如果是Few-shot 呢，怎么用Prototypical Network 解决呢。如右上角，我们把每个类别的几个图片用CNN 抽出的embedding 做average 来代表这个类别就好了。进来一个Testing Data 我们就看它和哪个class 的average 值更接近，就算作哪一个class 。</p>
<h3 id="matching-network"><a class="markdownIt-Anchor" href="#matching-network"></a> Matching Network</h3>
<p>Matching Network 和Prototypical Network 最不同的地方是，Matching Network 认为也许Training data 中的图片互相之间也是有关系的，所以用Bidirectional LSTM 处理Training data，把Training data 通过一个Bidirectional LSTM 也会得到对应的embedding ，然后的做法就和Prototypical Network 是一样的。</p>
<p><img src="/images/image-20201207144456982.png" alt="image-20201207144456982" / srcset="/images/LoadingImage.gif" data-src="/images/image-20201207144456982.png" class="lozad post-image"></p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1606.04080">https://arxiv.org/abs/1606.04080</a></p>
</blockquote>
<p>事实上是Matching Network 先被提出来的，然后人们觉得这个方法有点问题，问题出在Bidirectional LSTM 上，就是说如果输入Training data 的顺序发生变化，那得到的embedding 就变了，整个network 的辨识结果就可能发生变化，这是不合理的。</p>
<h3 id="relation-network"><a class="markdownIt-Anchor" href="#relation-network"></a> Relation Network</h3>
<p><img src="/images/image-20201207144856784.png" alt="image-20201207144856784" / srcset="/images/LoadingImage.gif" data-src="/images/image-20201207144856784.png" class="lozad post-image"></p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1711.06025">https://arxiv.org/abs/1711.06025</a></p>
</blockquote>
<p>这个方法和上面讲过的很相似，只是说我们之前通过人定的相似度计算方法计算每一类图片和测试图片的相似度，而Relation Network 是希望用另外的模型 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>g</mi><mi>ϕ</mi></msub></mrow><annotation encoding="application/x-tex">g_\phi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">ϕ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> 来计算相似度。</p>
<p>具体做法就是先通过一个 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>f</mi><mi>ϕ</mi></msub></mrow><annotation encoding="application/x-tex">f_\phi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.980548em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">ϕ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> 计算每个类别的以及测试数据的embedding ，然后把测试数据的embedding 接在所有类别embedding 后面丢入 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>g</mi><mi>ϕ</mi></msub></mrow><annotation encoding="application/x-tex">g_\phi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">ϕ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> 计算相似度分数。</p>
<h3 id="few-shot-learning-for-imaginary-data"><a class="markdownIt-Anchor" href="#few-shot-learning-for-imaginary-data"></a> Few-shot learning for Imaginary Data</h3>
<p>我们在做Few-Shot Learning 的时候的难点就是训练数据量太少了，那能不能让机器自己生成一些数据提供给训练使用呢。这就是Few-shot learning for Imaginary Data 的思想。</p>
<p><img src="/images/image-20201207151647201.png" alt="image-20201207151647201" / srcset="/images/LoadingImage.gif" data-src="/images/image-20201207151647201.png" class="lozad post-image"></p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1801.05401">https://arxiv.org/abs/1801.05401</a></p>
</blockquote>
<p>Learn 一个Generator <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>G</mi></mrow><annotation encoding="application/x-tex">G</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault">G</span></span></span></span> ，怎么Learn 出这个Generator 我们先不管，你给Generator 一个图片，他就会生成更多图片，比如说你给他三玖面无表情的样子，他就会YY出三玖卖萌的样子、害羞的样子、生气的样子等等。然后把生成的图片丢到Network 中做训练，结束。</p>
<p>实际上，真正做训练的时候Generator 和Network 是一起训的，这就是Few-shot learning for Imaginary Data 的意思。具体的做法，这里不展开了。</p>
<h1 id="meta-learning-traintest-as-rnn"><a class="markdownIt-Anchor" href="#meta-learning-traintest-as-rnn"></a> Meta Learning-Train+Test as RNN</h1>
<p>我们在讲Siamese Network 的时候说，你可以把Siamese Network 或其他Metric-based 的方法想成是Meta Learning ，但其实你是可以从其他更容易理解的角度来考虑这些方法。总的来说，我们就是要找一个function，这个function 可以做的到就是吃训练数据和测试数据，然后就可以吐出测试数据的预测结果。我们实际上用的Siamese Network 或者Prototypical Network 、Matching Network 等等的方法多可以看作我们为了实现这个目的做模型架构的变形。</p>
<p>现在我们想问问，有没有可能直接用常规的network 做出这件事？有的。</p>
<img src="/images/image-20201208132956910.png" alt="image-20201208132956910" style="zoom: 50%;" / srcset="/images/LoadingImage.gif" data-src="/images/image-20201208132956910.png" class="lozad post-image">
<p>用LSTM 把训练数据和测试数据吃进去，在最后输出测试数据的判别结果。训练图片通过一个CNN 得到一个embedding ，这个embedding 和这个图片的label（one-hot vector）做concatenate（拼接）丢入LSTM 中，Testing data 我们不知道label 怎么办，我们就用0 vector 来表示，然后同样丢入LSTM ，得到output 结束。这个方法用常规的LSTM 是train 不起来的，我们需要修改LSTM 的架构，有两个方法：</p>
<img src="/images/image-20201208134408015.png" alt="image-20201208134408015" style="zoom:50%;" / srcset="/images/LoadingImage.gif" data-src="/images/image-20201208134408015.png" class="lozad post-image">
<p>具体方法我们就不展开讲了，放出参考链接：</p>
<img src="/images/image-20201208134502970.png" alt="image-20201208134502970" style="zoom:50%;" / srcset="/images/LoadingImage.gif" data-src="/images/image-20201208134502970.png" class="lozad post-image">
<blockquote>
<p>One-shot Learning with Memory-Augmented Neural Networks</p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1605.06065">https://arxiv.org/abs/1605.06065</a></p>
<p>A Simple Neural Attentive Meta-Learner</p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1707.03141">https://arxiv.org/abs/1707.03141</a></p>
</blockquote>
<p>SNAIL 你看看他的架构图就能了解他在做什么，如上图右侧所示，和我们上面刚说过想法的是一样的，输入一堆训练数据给RNN 然后给他一个测试数据它输出预测结果，唯一不同的东西就是，它不是一个单纯的RNN ，它里面有在做回顾这件事，它在input 第二笔数据的时候会回去看第一笔数据，在input 第三笔数据的时候会回去看第一第二笔数据…在input 测试数据额时候会回去看所有输入的训练数据。</p>
<p>所以你会发现这件事是不是和prototypical network 和matching network 很相似呢，matching network 就是计算input 的图片和过去看过的图片的相似度，看谁最像，就拿那张最像的图片的label 当作network 的输出。SNAIL 的回顾过去看过的数据的做法就和matching network 的计算相似度的做法很像。</p>
<p>所以说，你虽然想用更通用的方法做到一个模型直接给出测试数据预测结果这件事，然后你发现你要改network 的架构，改完起了个名字叫SNAIL 但是他的思想变得和原本专门为这做到这件事设计的特殊的方法如matching network 几乎一样了，有点殊途同归的意思。</p>
<h2 id="experiment"><a class="markdownIt-Anchor" href="#experiment"></a> Experiment</h2>
<img src="/images/image-20201208140147667.png" alt="image-20201208140147667" style="zoom:50%;" / srcset="/images/LoadingImage.gif" data-src="/images/image-20201208140147667.png" class="lozad post-image">
<p>总之SNAIL 和其他方法相比都是最好的，没什么好说的了。</p>

  </div>
  <div>
  
  <div class="post-note note-info copyright" style="margin-top: 42px">
    <p><span style="font-weight: bold;">作者：</span><a target="_blank" rel="nofollow noopener noreferrer" href="https://ch3nye.top/about">Ch3nYe</a></p>
    <p><span style="font-weight: bold;">文章链接：</span><a target="_blank" rel="nofollow noopener noreferrer" href="https://ch3nye.top/Meta-Learning-Metric-based/">https://ch3nye.top/Meta-Learning-Metric-based/</a></p>
    <p><span style="font-weight: bold;">版权声明：</span>本博客所有文章除特别声明外，均采用<a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">CC BY-NC-SA 4.0 协议</a>。转载请注明出处！</p>
  </div>
  
  </div>
</article>
<div class="nav">
  
  <div class="nav-item-prev">
    <a href="/More-about-Auto-Encoder/" class="nav-link">
      <i class="iconfont icon-left nav-prev-icon"></i>
      <div>
        <div class="nav-label">上一篇</div>
        
        <div class="nav-title">More about Auto-Encoder </div>
        
      </div>
    </a>
  </div>
  
  
  <div class="nav-item-next">
    <a href="/Meta-Learning-Gradient-Descent-as-LSTM/" class="nav-link">
      <div>
        <div class="nav-label">下一篇</div>
        
        <div class="nav-title">Meta Learning-Gradient Descent as LSTM </div>
        
      </div>
      <i class="iconfont icon-right nav-next-icon"></i>
    </a>
  </div>
  
</div>

<div class="card card-content comment-card" style="margin-top: 16px;">
  <div class="comment-card-title">评论</div>
  
  <div id="lv-container" data-id="city" data-uid="MTAyMC80NjQ0Ny8yMjk1OA==">
    <script>
      (function (d, s) {
        var j, e = d.getElementsByTagName(s)[0];
        if (typeof LivereTower === 'function') {
          return;
        }
        j = d.createElement(s);
        j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
        j.defer = true;
        e.parentNode.insertBefore(j, e);
      })(document, 'script');
    </script>
  </div>

</div>

<div class="card card-content toc-card" id="mobiletoc">
  <div class="toc-header"><i class="iconfont icon-menu" style="padding-right: 2px;"></i>目录</div>
<ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#meta-learning-metric-based-approach"><span class="toc-text"> Meta Learning-Metric-based Approach</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#training-tasks-testing-tasks"><span class="toc-text"> Training Tasks &amp; Testing Tasks</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#siamese-network"><span class="toc-text"> Siamese Network</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#siamese-network-intuitive-explanation"><span class="toc-text"> Siamese Network - Intuitive Explanation</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#to-learn-more"><span class="toc-text"> To learn more…</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#n-way-fewone-shot-learning"><span class="toc-text"> N-way Few&#x2F;One-shot Learning</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#prototypical-network"><span class="toc-text"> Prototypical Network</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#matching-network"><span class="toc-text"> Matching Network</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#relation-network"><span class="toc-text"> Relation Network</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#few-shot-learning-for-imaginary-data"><span class="toc-text"> Few-shot learning for Imaginary Data</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#meta-learning-traintest-as-rnn"><span class="toc-text"> Meta Learning-Train+Test as RNN</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#experiment"><span class="toc-text"> Experiment</span></a></li></ol></li></ol>
</div></main>
          <aside class="left-column">
            
            <div class="card card-author">
              
<img src="/images/logo.png" class="author-img">

<p class="author-name">Ch3nYe</p>
<p class="author-description">如果有文章有任何错误请留言，谢谢🙏</p>
<div class="author-message">
  <a class="author-posts-count" href="/archives">
    <span>23</span>
    <span>文章</span>
  </a>
  <a class="author-categories-count" href="/categories">
    <span>5</span>
    <span>分类</span>
  </a>
  <a class="author-tags-count" href="/tags">
    <span>25</span>
    <span>标签</span>
  </a>
</div>

<div class="author-card-society">
  
    <div class="author-card-society-icon">
      <a target="_blank" rel="noopener" href="https://github.com/ch3nye/">
        <i class="iconfont icon-github society-icon"></i>
      </a>
    </div>
  
    <div class="author-card-society-icon">
      <a href="mailto:sud0su@163.com">
        <i class="iconfont icon-mail society-icon"></i>
      </a>
    </div>
  
</div>

            </div>
            
            <div class="sticky-tablet">
  
  
  <article class="display-when-two-columns spacer">
    <div class="card card-content toc-card">
      <div class="toc-header"><i class="iconfont icon-menu" style="padding-right: 2px;"></i>目录</div>
<ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#meta-learning-metric-based-approach"><span class="toc-text"> Meta Learning-Metric-based Approach</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#training-tasks-testing-tasks"><span class="toc-text"> Training Tasks &amp; Testing Tasks</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#siamese-network"><span class="toc-text"> Siamese Network</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#siamese-network-intuitive-explanation"><span class="toc-text"> Siamese Network - Intuitive Explanation</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#to-learn-more"><span class="toc-text"> To learn more…</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#n-way-fewone-shot-learning"><span class="toc-text"> N-way Few&#x2F;One-shot Learning</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#prototypical-network"><span class="toc-text"> Prototypical Network</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#matching-network"><span class="toc-text"> Matching Network</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#relation-network"><span class="toc-text"> Relation Network</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#few-shot-learning-for-imaginary-data"><span class="toc-text"> Few-shot learning for Imaginary Data</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#meta-learning-traintest-as-rnn"><span class="toc-text"> Meta Learning-Train+Test as RNN</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#experiment"><span class="toc-text"> Experiment</span></a></li></ol></li></ol>
    </div>
  </article>
  
  
  <article class="card card-content categories-widget">
    <div class="categories-card">
  <div class="categories-header"><i class="iconfont icon-fenlei" style="padding-right: 2px;"></i>分类</div>
  <div class="categories-list">
    
      <a href="/categories/备忘">
        <div class="categories-list-item">
          备忘
          <span class="categories-list-item-badge">1</span>
        </div>
      </a>
    
      <a href="/categories/李宏毅机器学习笔记">
        <div class="categories-list-item">
          李宏毅机器学习笔记
          <span class="categories-list-item-badge">14</span>
        </div>
      </a>
    
      <a href="/categories/论文阅读">
        <div class="categories-list-item">
          论文阅读
          <span class="categories-list-item-badge">3</span>
        </div>
      </a>
    
      <a href="/categories/笔记">
        <div class="categories-list-item">
          笔记
          <span class="categories-list-item-badge">4</span>
        </div>
      </a>
    
      <a href="/categories/实战">
        <div class="categories-list-item">
          实战
          <span class="categories-list-item-badge">1</span>
        </div>
      </a>
    
  </div>
</div>
  </article>
  
  <article class="card card-content tags-widget">
    <div class="tags-card">
  <div class="tags-header"><i class="iconfont icon-biaoqian" style="padding-right: 2px;"></i>热门标签</div>
  <div class="tags-list">
    
    <a href="\tags\Next-Step-of-ML" title="Next-Step-of-ML"><div class="tags-list-item">Next-Step-of-ML</div></a>
    
    <a href="\tags\note" title="note"><div class="tags-list-item">note</div></a>
    
    <a href="\tags\ML" title="ML"><div class="tags-list-item">ML</div></a>
    
    <a href="\tags\Android" title="Android"><div class="tags-list-item">Android</div></a>
    
    <a href="\tags\笔记" title="笔记"><div class="tags-list-item">笔记</div></a>
    
    <a href="\tags\论文" title="论文"><div class="tags-list-item">论文</div></a>
    
    <a href="\tags\学习" title="学习"><div class="tags-list-item">学习</div></a>
    
    <a href="\tags\总结" title="总结"><div class="tags-list-item">总结</div></a>
    
    <a href="\tags\实战" title="实战"><div class="tags-list-item">实战</div></a>
    
    <a href="\tags\crack" title="crack"><div class="tags-list-item">crack</div></a>
    
    <a href="\tags\ELF" title="ELF"><div class="tags-list-item">ELF</div></a>
    
    <a href="\tags\二进制" title="二进制"><div class="tags-list-item">二进制</div></a>
    
    <a href="\tags\Linux" title="Linux"><div class="tags-list-item">Linux</div></a>
    
    <a href="\tags\Hot-Patch" title="Hot-Patch"><div class="tags-list-item">Hot-Patch</div></a>
    
    <a href="\tags\污点分析" title="污点分析"><div class="tags-list-item">污点分析</div></a>
    
    <a href="\tags\比特币" title="比特币"><div class="tags-list-item">比特币</div></a>
    
  </div>
</div>
  </article>
  
  
</div>
          </aside>
          <aside class="right-column">
            <div class="sticky-widescreen">
  
  
  <article class="card card-content toc-card">
    <div class="toc-header"><i class="iconfont icon-menu" style="padding-right: 2px;"></i>目录</div>
<ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#meta-learning-metric-based-approach"><span class="toc-text"> Meta Learning-Metric-based Approach</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#training-tasks-testing-tasks"><span class="toc-text"> Training Tasks &amp; Testing Tasks</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#siamese-network"><span class="toc-text"> Siamese Network</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#siamese-network-intuitive-explanation"><span class="toc-text"> Siamese Network - Intuitive Explanation</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#to-learn-more"><span class="toc-text"> To learn more…</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#n-way-fewone-shot-learning"><span class="toc-text"> N-way Few&#x2F;One-shot Learning</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#prototypical-network"><span class="toc-text"> Prototypical Network</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#matching-network"><span class="toc-text"> Matching Network</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#relation-network"><span class="toc-text"> Relation Network</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#few-shot-learning-for-imaginary-data"><span class="toc-text"> Few-shot learning for Imaginary Data</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#meta-learning-traintest-as-rnn"><span class="toc-text"> Meta Learning-Train+Test as RNN</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#experiment"><span class="toc-text"> Experiment</span></a></li></ol></li></ol>
  </article>
  
  
  <article class="card card-content">
    <div class="recent-posts-card">
  <div class="recent-posts-header"><i class="iconfont icon-wenzhang_huaban" style="padding-right: 2px;"></i>最近文章</div>
  <div class="recent-posts-list">
    
      <div class="recent-posts-item">
        <div class="recent-posts-item-title">2021-02-08</div>
        <a href="/Linux二进制分析笔记(ELF)/"><div class="recent-posts-item-content">Linux二进制分析笔记(ELF)</div></a>
      </div>
    
      <div class="recent-posts-item">
        <div class="recent-posts-item-title">2021-02-01</div>
        <a href="/【实战】某视频app的crack尝试/"><div class="recent-posts-item-content">【实战】某视频app的crack尝试</div></a>
      </div>
    
      <div class="recent-posts-item">
        <div class="recent-posts-item-title">2021-01-29</div>
        <a href="/Note-Automatic-Hot-Patch-Generation-for-Android-Kernels/"><div class="recent-posts-item-content">Note《Automatic Hot Patch Generation for Android Kernels》</div></a>
      </div>
    
      <div class="recent-posts-item">
        <div class="recent-posts-item-title">2021-01-20</div>
        <a href="/Note-FANS-Fuzzing-Android-Native-System-Services/"><div class="recent-posts-item-content">Note《FANS Fuzzing Android Native System Services via Automated Interface Analysis》</div></a>
      </div>
    
  </div>
</div>
  </article>
  
  
</div>
          </aside>
        </div>
      </div>
    </div>
  </div>
  
  <footer class="footer">
  <div class="footer-container">
    <div>
      <div class="footer-dsc">
        <span>Copyright ©
          
          2020 -
          
          2021
        </span>
        &nbsp;
        <a href="/" class="footer-link">ch3nye's blog </a>
      </div>
    </div>

    
    <div class="footer-dsc">
      
      Powered by
      <a href="https://hexo.io/" class="footer-link" target="_blank" rel="nofollow noopener noreferrer">&nbsp;Hexo </a>
      
      
      <span>&nbsp;|&nbsp;</span>
      
      
      Theme -
      <a href="https://github.com/theme-kaze" class="footer-link" target="_blank"
        rel="nofollow noopener noreferrer">&nbsp;Kaze</a>
      
    </div>
    
    
    
    
      <div class="footer-dsc">
        
        本站总访问量<span id="busuanzi_value_site_pv"></span>次
        
        
        <span>&nbsp;|&nbsp;</span>
        
        
        本站总访客数<span id="busuanzi_value_site_uv"></span>次
        
      </div>
      
    
</footer>
  <a role="button" id="scrollbutton" class="basebutton"  aria-label="回到顶部">
  <i class="iconfont icon-arrowleft button-icon"></i>
</a>
<a role="button" id="menubutton" class="basebutton">
  <i class="iconfont icon-menu button-icon"></i>
</a>
<a role="button" id="popbutton" class="basebutton" aria-label="控制中心">
  <i class="iconfont icon-expand button-icon"></i>
</a>
<a role="button" id="darkbutton" class="basebutton darkwidget" aria-label="夜色模式">
  <i class="iconfont icon-weather button-icon"></i>
</a>
<a role="button" id="searchbutton" class="basebutton searchwidget" aria-label="搜索">
  <i class="iconfont icon-search button-icon"></i>
</a>

  
  
  

  
  
    
<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css">

  

  
  
  <script>
  var addImgLayout = function () {
    var img = document.querySelectorAll('.post-content img');
    var i;
    for (i = 0; i < img.length; i++) {
      var wrapper = document.createElement('a');
      wrapper.setAttribute('data-fslightbox', 'gallery');
      wrapper.setAttribute('href', img[i].getAttribute('data-src'));
      wrapper.setAttribute('aria-label', 'illustration');
      wrapper.style.cssText = 'width: 100%; display: flex; justify-content: center;';
      img[i].before(wrapper);
      wrapper.append(img[i]);
    }
    refreshFsLightbox();
  }
</script>
<script>loadScript("//cdn.jsdelivr.net/npm/fslightbox@3.1.0/index.min.js", addImgLayout)</script>
  
  
  
<script src="/js/main.js"></script>

  
  <script>loadScript("/js/lib/busuanzi.min.js")</script>
  
  
  <script>
    var addLazyload = function () {
      var observer = lozad('.lozad', {
        load: function (el) {
          el.srcset = el.getAttribute('data-src');
        },
        loaded: function (el) {
          el.classList.add('loaded');
        }
      });
      observer.observe();
    }
  </script>
  <script>loadScript("/js/lib/lozad.min.js", addLazyload)</script>
  
  
  <script>
    var googleAnalytics = function() {
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'G-WHGL11014T');
    }
  </script>
  <script>loadScript("https://www.googletagmanager.com/gtag/js?id=" + "G-WHGL11014T", googleAnalytics)</script>
  
</body>

</html>